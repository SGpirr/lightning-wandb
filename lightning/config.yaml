# lightning.pytorch==2.0.2
fit:
  seed_everything: 4
  trainer:
    accelerator: 'gpu'
    strategy: 'ddp'
    devices: -1
    num_nodes: 1
    precision: '16-mixed'
    logger:
      - class_path: lightning.pytorch.loggers.WandbLogger
        init_args:
          log_model: true
          project: 'MNIST_test'
          save_dir: '../logs'
          # name: 'version1'
          settings:
            class_path: wandb.Settings
            init_args:
              code_dir: "."

    callbacks:
      - class_path: lightning.pytorch.callbacks.EarlyStopping
        init_args:
          patience: 5
          monitor: 'valid_acc'
      - class_path: lightning.pytorch.callbacks.ModelCheckpoint
        init_args:
          monitor: 'valid_acc'
          mode: 'max'
          save_top_k: 2
          filename: 'mnist-{epoch:02d}-{valid_acc:.5f}'
          # auto_insert_metric_name: true
          
    fast_dev_run: false
    max_epochs: 5
    min_epochs: null
    max_steps: -1
    min_steps: null
    max_time: null
    limit_train_batches: null
    limit_val_batches: null
    limit_test_batches: null
    limit_predict_batches: null
    overfit_batches: 0.0
    val_check_interval: null
    check_val_every_n_epoch: 1
    num_sanity_val_steps: null
    log_every_n_steps: null
    enable_checkpointing: null
    enable_progress_bar: null
    enable_model_summary: null
    accumulate_grad_batches: 1
    gradient_clip_val: null
    gradient_clip_algorithm: null
    deterministic: null
    benchmark: null
    inference_mode: true
    use_distributed_sampler: true
    profiler: null
    detect_anomaly: false
    barebones: false
    plugins: null
    sync_batchnorm: false
    reload_dataloaders_every_n_epochs: 0
    default_root_dir: null

  ckpt_path: null
  
  model:
    n_layer_1: 128
    n_layer_2: 256
    lr: 1e-3
